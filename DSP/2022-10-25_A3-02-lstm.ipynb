{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyvfgZLr6q1yOXRXzbnquU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Introduction"],"metadata":{"id":"JzOQmEXW7gOs"}},{"cell_type":"markdown","source":["In the second part of the assignment, we train a deep neural network (LSTM) for multi-class classification on the class corpus."],"metadata":{"id":"60GSgcVT7kOl"}},{"cell_type":"markdown","source":["Text, that is, a sequence of words is a fundamentally different type of data when compared with tabular data or images/videos. For text neither is the input size fixed (e.g., movie reviews of different lengths) nor is the output fixed (e.g., binary classification or translated text). Deep learning with text is hence a case of variable inputs - variable outputs and needs special architectures (e.g., RNN's, Transformers)."],"metadata":{"id":"6_u4sgjFAwKG"}},{"cell_type":"markdown","source":["The workflow to model text, however, remains the same - convert the documents to a vectorized representation and use this representation for a downstream task (e.g., sentiment analysis)."],"metadata":{"id":"4MsHy0TlBdVN"}},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow as tf\n","\n","from pathlib import Path"],"metadata":{"id":"2RZnrdBvsQXx","executionInfo":{"status":"ok","timestamp":1666696013971,"user_tz":-330,"elapsed":2690,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"5FEbiBEI74yr"}},{"cell_type":"markdown","source":["Let us begin by preparing the data required to build the model."],"metadata":{"id":"gd71brOg7xPi"}},{"cell_type":"code","source":["data_file = '/content/DSP453_ClassCorpus_v1.csv'"],"metadata":{"id":"3UwiVJ5-s_Ee","executionInfo":{"status":"ok","timestamp":1666696013972,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class_corpus = pd.read_csv(data_file)"],"metadata":{"id":"lar1_MOGtG2Y","executionInfo":{"status":"ok","timestamp":1666696013972,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class_corpus.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grAjtB1WtMR3","executionInfo":{"status":"ok","timestamp":1666696013973,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"201473f1-6dcc-4c7a-c38b-f2a4c8f522f0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 100 entries, 0 to 99\n","Data columns (total 8 columns):\n"," #   Column                    Non-Null Count  Dtype \n","---  ------                    --------------  ----- \n"," 0   Doc_ID                    100 non-null    int64 \n"," 1   DSI_Title                 100 non-null    object\n"," 2   Text                      100 non-null    object\n"," 3   Submission File Name      100 non-null    object\n"," 4   Student Name              100 non-null    object\n"," 5   Genre of Movie            100 non-null    object\n"," 6   Review Type (pos or neg)  100 non-null    object\n"," 7   Movie Title               100 non-null    object\n","dtypes: int64(1), object(7)\n","memory usage: 6.4+ KB\n"]}]},{"cell_type":"markdown","source":["# Sentiment Analysis"],"metadata":{"id":"Z2CaQjG2vfxl"}},{"cell_type":"markdown","source":["As an example of multi-class classification, let us look at building a deep neural network to infer the sentiment of a review from the text of the review. Along the way, we will look at the architecture of a recurrent neural network."],"metadata":{"id":"4IUCz3cI77UL"}},{"cell_type":"markdown","source":["The [latest tensorflow API](https://www.tensorflow.org/tutorials/keras/text_classification) unifies dataset structures for text and images (see screenshot below). However, we do not have the data in this format. We will first bring our data to the format that is requried by Tensorflow. For large scale projects it is beneficial to use this format, since document level errors can be easily localized. "],"metadata":{"id":"9UiuLe6Fvr1u"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"BkltjBp5v2Bu"}},{"cell_type":"markdown","source":["## Prepare Data"],"metadata":{"id":"lyBpXZn6vkRs"}},{"cell_type":"code","source":["root_examples_dir = Path('/content/examples/')"],"metadata":{"id":"CwnSu7TS066H","executionInfo":{"status":"ok","timestamp":1666696013973,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["root_examples_dir.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"AZVrT_JC1B1P","executionInfo":{"status":"ok","timestamp":1666696013973,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pos_examples_dir = root_examples_dir / 'positive'\n","neg_examples_dir = root_examples_dir / 'negative'"],"metadata":{"id":"3vrOUerUvips","executionInfo":{"status":"ok","timestamp":1666696013974,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["pos_examples_dir.mkdir(parents=True, exist_ok=True)\n","neg_examples_dir.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"xZlac4kXwSS0","executionInfo":{"status":"ok","timestamp":1666696014779,"user_tz":-330,"elapsed":813,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class_corpus_pos = class_corpus.loc[class_corpus[\"Review Type (pos or neg)\"] == 'Positive', 'Text']\n","class_corpus_neg = class_corpus.loc[class_corpus[\"Review Type (pos or neg)\"] == 'Negative', 'Text']"],"metadata":{"id":"QVFZMGbtvE_u","executionInfo":{"status":"ok","timestamp":1666696014780,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class_corpus_pos.shape, class_corpus_neg.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hev64g4x0ES","executionInfo":{"status":"ok","timestamp":1666696014780,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"22aa37b5-4cfb-4839-cfca-71e83adbb004"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((50,), (50,))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["for review_index, review in zip(class_corpus_pos.index, class_corpus_pos):\n","    with open(pos_examples_dir / (str(review_index) + \".txt\"), \"w\") as f:\n","        f.write(review)"],"metadata":{"id":"H4HGouPtyH4j","executionInfo":{"status":"ok","timestamp":1666696014781,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for review_index, review in zip(class_corpus_neg.index, class_corpus_neg):\n","    with open(neg_examples_dir / (str(review_index) + \".txt\"), \"w\") as f:\n","        f.write(review)"],"metadata":{"id":"5hDND0BdzzLZ","executionInfo":{"status":"ok","timestamp":1666696014781,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["len(list(pos_examples_dir.glob(\"*.txt\"))), len(list(neg_examples_dir.glob(\"*.txt\"))) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gc4uUdswz8L4","executionInfo":{"status":"ok","timestamp":1666696014781,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"9c52b8ef-1493-4191-c4d4-f0e76f5daf47"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50, 50)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["To create a text dataset from the corpus, we will need to specify the batch size."],"metadata":{"id":"oBKwQu0l83Wq"}},{"cell_type":"code","source":["BATCH_SIZE = 3"],"metadata":{"id":"WFfqFWzq0f6A","executionInfo":{"status":"ok","timestamp":1666696014782,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["raw_train_ds = tf.keras.utils.text_dataset_from_directory(root_examples_dir, \n","                                                          batch_size=BATCH_SIZE, \n","                                                          validation_split=0.2, \n","                                                          subset='training', \n","                                                          seed=20130810)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RglDsffX0jXA","executionInfo":{"status":"ok","timestamp":1666696016745,"user_tz":-330,"elapsed":1971,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"72819463-d9df-4f2f-b468-934e51c3ccde"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 100 files belonging to 2 classes.\n","Using 80 files for training.\n"]}]},{"cell_type":"code","source":["for text_batch, label_batch in raw_train_ds.take(1):\n","  for i in range(3):\n","    print(\"Review\", text_batch.numpy()[i])\n","    print(\"Label\", label_batch.numpy()[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZay2ytM1nt3","executionInfo":{"status":"ok","timestamp":1666696016746,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"73f2e4d3-c94e-4591-ed88-951182fedd04"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Review b'\"Watching a Jordan Peele film is a uniquely unsettling experience. This is not just because \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdGet Out,\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd his brilliant debut, and now \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdUs,\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd are smart-and-scary horror movies. It is also because, after all the clues he dropped like so many breadcrumbs in \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdGet Out,\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd you cannot simply sit back and watch \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdUs.\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd You find yourself endlessly searching for hints, for tidbits, for the at-first-glance throwaway image that ultimately will unlock the secrets of the story. It\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds relentless \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd and it\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds thrilling. Which is not to say that \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdUs\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd is the equal of \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdGet Out.\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd Few films are. But \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdUs\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd is a strong film in its own right, a sign of Peele\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds confidence as a filmmaker (here he tackles class division, in a different way than he did racism in \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdGet Out\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd). It\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds also a sign that we can be confident he\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdll make us think while making us squirm. And maybe scream a little. Us\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd begins in 1986, at night at a carnival on the boardwalk on the beach in Santa Cruz, California. A little girl wanders from her father, who is drinking beer and playing Whac-A-Mole. She walks almost trance-like to the beach, and winds up in a fun-house, hall-of-mirrors-type attraction. Lost inside, she sees something that will haunt her for the rest of her life (and eventually haunt the audience). Then we\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdre in the present, with the girl, Adelaide (Lupita Nyong\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdo) grown up, married to Gabe (Winston Duke), with a daughter, Zora (Shahadi Wright Joseph) and son Jason (Evan Alex). They\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdre on the way to their summer home in \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd Santa Cruz. (If cinematographer Mike Gioulakis\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd overhead shot of the family driving to their vacation isn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt meant to evoke the opening of Stanley Kubrick\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdThe Shining,\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd it\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds a happy accident.). Adelaide really doesn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt want to go to the beach, but Gabe, an amiable goof, talks her into it. They meet their friends Josh and Kitty (Tim Heidecker and Elisabeth Moss) and their twin daughters, a family just a little more well-off enough to bug Gabe. A couple of unusual things happen, enough to rattle Adelaide. Peele, who wrote and produced the film, in addition to directing it, periodically flashes back to the night in 1986 that so shaped her life. That night, the power goes out in their vacation home (Josh and Kitty have a backup generator, Gabe notes with annoyance), and Jason comes into his parents\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd room with alarm: There is a family standing in their driveway. It\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds not just any family; if you\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdve seen the trailer, you know that it\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds them, or their doppelg\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdngers. The film for a time becomes an exercise in home-invasion horror \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd something at which Peele excels. (There are nods to several horror films here, recognizable but never overwhelming Peele\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds unique vision.) There are many surprises to follow, and many more scares, but underlying everything is a message \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd a warning, really \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd pitting the haves vs. the have-nots, a class division that has broken out into full-on class warfare. The reasons for this grow a little fuzzy as Peele tries to explain things late in the game; that part of the film isn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt entirely successful, though it certainly doesn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt lack for ambition. The acting is fantastic \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd playing dual roles is doubtless an actor\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds dream. But Nyong\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdo is particularly outstanding. Peele relies on her to carry the film, both as a kind of action hero and her own worst enemy, and if you\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdre looking for a message there, well, you can find one. Peele\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds visual audacity is at times breathtaking, and always serves a greater purpose. There is a beautiful overhead shot of the family walking along the beach, carrying their supplies, casting long shadows. There\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds no way to know in the moment you\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdre admiring this that it carries meaning that informs the rest of the film. That\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds just terrific filmmaking. And even if \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdUs\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd can\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt match the standard Peele set with \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdGet Out,\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd it\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds another reason to be excited about whatever he comes up with next.\"'\n","Label 1\n","Review b'\"This movie was not the work of experts, but a group of random amateurs who saw too many Steven Seagal movies and wanted to cash in on prejudices held on \"\"SOME\"\" of these actors\\' past successes. The IMDb score tricked me into thinking this was worth the time, but let me give feedback appropriately by mentioning the best things first and then go on to the worst parts. The only good (funny) part: When the protagonist contacts a previous CIA contact, that turns out to be a fraud, he shoots the man\\'s innocent wife in the arm, in order to get information. As my bro said, she was depicted as a French housewife, whose life held no value. This was pure dark humor, that got me laughing, because this cutthroat abusive behavior is not the behavior you expect of someone (supposedly) ex-CIA, but expect of a retired pimp. Then the worst parts: The disregard of all life forms that are not American. It is as though this movie hopes to accomplish complete disregard for all human life forms outside the USA, he kills so many people and ignores the suffering of so many girls that have the same age as his daughter that you end up hoping there will be some mention of these factors in the last minute of the movie. Nonetheless, in the end all that matters is the safe return of the spoiled American brat. Nobody cared for the other girls used as prostitutes, because they were not American. A note to the writer: this move plays out in France and THIS IS NOT THE MATRIX OTHER LIFE FORMS DO EXIST!!!!! The plot. As there was none, it was all predictable if you ever saw a Steven Seagal movie, except most of those actually have some form of content... The movie The innocence of M. was a movie with a plot of a similar level. Portrait of France. This country known for its refined culture is portrayed as a poverty stricken third world country, that happens to host the Louvre and some museums. This is confirmed by, the protagonist never considering contacting authorities and instead decides to kill all criminals he meets himself. The Credibility. Ex-CIA? Yeah right, for the sake of the USA I hope the CIA has more Intelligence... like I said, he was more like a retired pimp who\\'s stash got busted and was out for revenge. This movie does not attempt to have you believe 10 seconds of its story line, it\\'s all fantasy of an overexcited Steven Seagal fan. The acting. After the first scene I hoped his daughter would just die, because this spoiled brat can\\'t act! She sucked in Lost and still does. Furthermore, everything resembles a Steven Seagal movie, the only good actors in this movie are possibly the French female addict, he only helps because she is wearing his daughter\\'s jacket (BTW, she gets discarded after the protagonist gets his information). Furthermore, the protagonist was mediocre at acting, he used the script as a bible and unfortunately his face only knows 3 expressions: anger, anxiety and satisfaction. But, 80% of the time he just portrayed an angry tourist. My recommendation is if you have an IQ above 45, this movie will not meet your expectations of a movie made by people with an IQ above 20. All this movie tries to inspire is to randomly kill people while you\\'re in a foreign country on vacation or looking for your spoiled slightly retarded daughter. This piece of trash gives all Americans a bad name and does not teach anybody anything, save yourself, the time, money and breath it takes to deal with this product made by amateur American Hollywood residents without a passport.\"'\n","Label 0\n","Review b'\"Holmes and Watson review: a lumbering Sherlockian knockdown. Will Ferrell and John C. Reilly ape Conan Doyle\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds Victorian detective in an improbably dreadful comedic misfire. Ever since the days of Basil Rathbone and Nigel Bruce, there has been a vein of character comedy in screen portrayals of Conan Doyle\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds great sleuth. As the figure of audience identification, Dr Watson registers both admiration for Sherlock Holmes\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds extraordinary powers of deduction and intermittent exasperation at his arrogance and hauteur. It\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds easy to see the potential for pointed exaggeration, as in Gene Wilder\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds 1975 The Adventures of Sherlock Holmes\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd Smarter Brother or Thom Eberhardt\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds 1988 Without a Clue, where the humour springs from the legendary Holmes being not quite as sharp as we\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdve been led to believe. Enter the established comedy duo of Will Ferrell and John C. Reilly, as Holmes and Watson respectively, and the conceit this time seems to be that the actors\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd goofball rudery and physical knockabout \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd seen in previous pairings Talladega Nights (2006) and Step Brothers (2008) \\xc3\\xaf\\xc2\\xbf\\xc2\\xbd will generate gales of laughter when shoehorned into the seemingly inappropriate context of a Conan Doyle-style detective saga. Unfortunately, howls of anguish are the result, since poor material, ill-timed performances and an all-encompassing air of desperate cluelessness create a mirth-free zone. Part of the problem is that writer-director Etan Cohen (not Ethan Coen, an important distinction) doesn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt quite know what to do with Ferrell\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds facility for playing pompous fools.Here then are gags where the great detective\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds elaborate deductions cause only chaos, notably in a tiresomely extended set piece involving the pursuit of an escaped disease-carrying mosquito; yet there are also key plot points where Holmes\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds convention-defying conclusions (that the Moriarty brought to trial is an impostor, for instance), while unlikely, prove absolutely correct. There is no consistency in the telling, making it unclear how seriously we should take anything. A dismal sense of \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdso what?\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd sets in early, and certainly isn\\xc3\\xaf\\xc2\\xbf\\xc2\\xbdt helped by direction that struggles to shape the proceedings with any sense of urgency or tension. It all stands or falls, therefore, on the gags themselves, and there\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds very little here that hits the mark. Various bits of business show the central duo \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdinventing\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd the selfie (with an ungainly box camera) and drunk texting (via telegram, which Holmes dubs the \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdintoxigraph\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd), while elsewhere the film looks to poke fun at changes in social attitudes, underlining Holmes\\xc3\\xaf\\xc2\\xbf\\xc2\\xbds liberal use of cocaine and his inability to conceive that a woman can actually be a qualified doctor. The comic intentions are obvious but barely warrant a smile, which makes for a long 90 minutes, with the occasional puerile pratfalls and sheer waste of Ralph Fiennes, Rebecca Hall and Kelly Macdonald only intensifying the gloom. Glaring anachronisms, such as a gramophone playing The Righteous Brothers\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd Unchained Melody in a senseless Ghost-themed skit, or the launch of the Titanic a good 30 years too early (cue a truly pitiful Billy Zane cameo as \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdhimself\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd), indicate a film scrabbling around for something, anything, to raise a chuckle. Alas, without success. With apologies to Jordan Peele, \\xc3\\xaf\\xc2\\xbf\\xc2\\xbdthe sunken place\\xc3\\xaf\\xc2\\xbf\\xc2\\xbd has found its cinematic form. \"'\n","Label 0\n"]}]},{"cell_type":"code","source":["print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n","print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRCQg3_81qxw","executionInfo":{"status":"ok","timestamp":1666696016746,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"86423e27-3ff2-4818-86d1-32b655414cb1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 0 corresponds to negative\n","Label 1 corresponds to positive\n"]}]},{"cell_type":"code","source":["raw_val_ds = tf.keras.utils.text_dataset_from_directory(root_examples_dir, \n","                                                        batch_size=BATCH_SIZE, \n","                                                        validation_split=0.2, \n","                                                        subset='validation', \n","                                                        seed=20130810)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2bJSU6n1yI-","executionInfo":{"status":"ok","timestamp":1666696017498,"user_tz":-330,"elapsed":757,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"b195466f-2f0e-4b3f-8dc9-c4fbdfb9b9f1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 100 files belonging to 2 classes.\n","Using 20 files for validation.\n"]}]},{"cell_type":"markdown","source":["[To speed up training](https://www.tensorflow.org/guide/data_performance), it is beneficial to shuffle, cache and prefetch the samples."],"metadata":{"id":"ARUs0-hS9ZP7"}},{"cell_type":"code","source":["train_ds = (raw_train_ds.shuffle(buffer_size=raw_train_ds.cardinality().numpy())\n","                        .cache()\n","                        .prefetch(buffer_size=tf.data.AUTOTUNE))\n","\n","val_ds = (raw_val_ds.shuffle(buffer_size=raw_train_ds.cardinality().numpy())\n","                    .cache()\n","                    .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"BtIbtMD83wAo","executionInfo":{"status":"ok","timestamp":1666696017498,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## Vectorize"],"metadata":{"id":"JEEuEOJp2IH3"}},{"cell_type":"markdown","source":["To vectorize the reviews, we use the [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) class. We can cap the vocabulary size to limit the tokens used for modeling to the most frequently appearing ones."],"metadata":{"id":"CgMs1Z87PKuV"}},{"cell_type":"code","source":["VOCAB_SIZE = 5000"],"metadata":{"id":"zUoXdt0c6m7U","executionInfo":{"status":"ok","timestamp":1666696017498,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE, \n","                                            standardize=\"lower_and_strip_punctuation\", \n","                                            pad_to_max_tokens=True)"],"metadata":{"id":"grVHtxoa6yBi","executionInfo":{"status":"ok","timestamp":1666696017499,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Note that beyond the default, we could change the `standardize` parameter to use a [custom function](https://www.tensorflow.org/tutorials/keras/text_classification)."],"metadata":{"id":"FlmXd2wWA9TV"}},{"cell_type":"code","source":["encoder.adapt(train_ds.map(lambda text, label: text), \n","              batch_size= None)"],"metadata":{"id":"5u7Mfo_g66cx","executionInfo":{"status":"ok","timestamp":1666696017499,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["encoded_example = encoder('encanto we dont talk about bruno no no').numpy()\n","encoded_example[:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivMatfRh9CsJ","executionInfo":{"status":"ok","timestamp":1666696017499,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"4301c8fb-f7b9-4040-e584-db6a1053d4ce"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   1,   63,  134, 1340,   55,    1,   64,   64])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(\"1340: \", encoder.get_vocabulary()[1340])\n","print(\"1: \", encoder.get_vocabulary()[1])\n","\n","print(f'Vocabulary size: {len(encoder.get_vocabulary())}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad5kJGMr9cjX","executionInfo":{"status":"ok","timestamp":1666696017499,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"7bda8493-30a4-4fe8-8fd8-0399fa2bfc86"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["1340:  talk\n","1:  [UNK]\n","Vocabulary size: 5000\n"]}]},{"cell_type":"markdown","source":["Note how a special token `[UNK]` is used to identify out of vocabulary (OOV) words."],"metadata":{"id":"bnEqg6S9BwJ1"}},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"yi6D2EgP34HX"}},{"cell_type":"code","source":["NUM_CLASSES = 2"],"metadata":{"id":"EpXqaHXs45bF","executionInfo":{"status":"ok","timestamp":1666696017500,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["As we have done so far, we make the encoder a part of the model. This ensures that the test data follows the patterns encoded during training (i.e., no data leakage)."],"metadata":{"id":"bGemYjmhBN5b"}},{"cell_type":"markdown","source":["The [LSTM cell](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) augments a vanilla RNN cell by incorporating among other things a gradient flow highway. If the LSTM cell is used as an intermediate layer, then it needs to return a sequence that is used by another downstream LSTM layer as an input (default is to return [the output of the last timestep](https://www.tensorflow.org/guide/keras/rnn))."],"metadata":{"id":"2Y800usIROEH"}},{"cell_type":"code","source":["model = tf.keras.Sequential([# encoder generates one hot encoded corpus based on the vocabulary\n","                             encoder, \n","                             # Embedding layer projects this vocabulary down to a smaller dimension\n","                             tf.keras.layers.Embedding(len(encoder.get_vocabulary()), \n","                                                       64, \n","                                                       mask_zero=True), \n","                             # The first LSTM layer uses the outputs from the embedding layer\n","                             # as the input sequence\n","                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  \n","                                                                                return_sequences=True, \n","                                                                                dropout=0.3)),\n","                             # The second LSTM layer uses the outputs from the first LSTM\n","                             # layer as the input sequence\n","                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,\n","                                                                                dropout=0.3)),\n","                             # The Dense layer uses outputs from the last time step of \n","                             # the LSTM layer\n","                             tf.keras.layers.Dense(64, activation='relu'),\n","                             # The final layer outputs the \n","                             tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')  \n","])"],"metadata":{"id":"j8lPxu3O4HId","executionInfo":{"status":"ok","timestamp":1666696023611,"user_tz":-330,"elapsed":6116,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Text is a special kind of a time-series where the context around the word in both directions encodes meaningful information. Hence, when working with text we use a [Bidirectional layer](https://www.tensorflow.org/guide/keras/rnn#bidirectional_rnns). The Bidirectional layer copies the LSTM layer and processes inputs in opposing orders as they run through the network. It then concatenates the forward layer output and backward layer output.\n"],"metadata":{"id":"4aYY42luyNfc"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FJbevzO4-vM","executionInfo":{"status":"ok","timestamp":1666696023612,"user_tz":-330,"elapsed":21,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"aea1e489-30d8-462e-fb23-f09d3d89e0f4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," text_vectorization (TextVec  (None, None)             0         \n"," torization)                                                     \n","                                                                 \n"," embedding (Embedding)       (None, None, 64)          320000    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, None, 128)        66048     \n"," l)                                                              \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 64)               41216     \n"," nal)                                                            \n","                                                                 \n"," dense (Dense)               (None, 64)                4160      \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 431,554\n","Trainable params: 431,554\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-5),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])"],"metadata":{"id":"uRvFRit_5MO8","executionInfo":{"status":"ok","timestamp":1666696023612,"user_tz":-330,"elapsed":14,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_ds,\n","                    epochs=200,\n","                    validation_data=val_ds,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n","                                                                patience=5)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfZF7Biu5R8Y","executionInfo":{"status":"ok","timestamp":1666696076539,"user_tz":-330,"elapsed":52941,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"2a98bbbf-8d59-48a3-f02f-9f04ec84ffef"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","27/27 [==============================] - 29s 317ms/step - loss: 0.6931 - accuracy: 0.4500 - val_loss: 0.6926 - val_accuracy: 0.6000\n","Epoch 2/200\n","27/27 [==============================] - 4s 132ms/step - loss: 0.6930 - accuracy: 0.4500 - val_loss: 0.6926 - val_accuracy: 0.6000\n","Epoch 3/200\n","27/27 [==============================] - 3s 130ms/step - loss: 0.6931 - accuracy: 0.4875 - val_loss: 0.6926 - val_accuracy: 0.6000\n","Epoch 4/200\n","27/27 [==============================] - 3s 131ms/step - loss: 0.6927 - accuracy: 0.5750 - val_loss: 0.6926 - val_accuracy: 0.6000\n","Epoch 5/200\n","27/27 [==============================] - 4s 133ms/step - loss: 0.6925 - accuracy: 0.6125 - val_loss: 0.6926 - val_accuracy: 0.6000\n","Epoch 6/200\n","27/27 [==============================] - 4s 140ms/step - loss: 0.6927 - accuracy: 0.5750 - val_loss: 0.6926 - val_accuracy: 0.6000\n"]}]},{"cell_type":"markdown","source":["# References\n","\n","1. [Illustrated Guide to LSTM](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n","2. [Understanding LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"],"metadata":{"id":"GtQ74k63KGT0"}}]}