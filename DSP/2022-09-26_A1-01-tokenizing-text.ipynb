{"cells":[{"cell_type":"code","source":["! pip install session_info"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgEQ4TvmxC2b","executionInfo":{"status":"ok","timestamp":1664463243281,"user_tz":-330,"elapsed":9477,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"0c4624c0-f300-484f-db36-f4ce67de9633"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting session_info\n","  Downloading session_info-1.0.0.tar.gz (24 kB)\n","Collecting stdlib_list\n","  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 938 kB/s \n","\u001b[?25hBuilding wheels for collected packages: session-info\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8048 sha256=cfbcc5f40fbe81469c7296158ac4d3dc73147b0fe76711375418f67e97ee88e2\n","  Stored in directory: /root/.cache/pip/wheels/bd/ad/14/6a42359351a18337a8683854cfbba99dd782271f2d1767f87f\n","Successfully built session-info\n","Installing collected packages: stdlib-list, session-info\n","Successfully installed session-info-1.0.0 stdlib-list-0.8.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"W5Sl2wTqw5Iu","executionInfo":{"status":"ok","timestamp":1664463246731,"user_tz":-330,"elapsed":1380,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["import nltk\n","import re\n","import session_info\n","\n","import pandas as pd\n","\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"BdSegZRpw5Ix","executionInfo":{"status":"ok","timestamp":1664463248643,"user_tz":-330,"elapsed":516,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"82094488-0af7-4a50-c083-aa9186780297"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<details>\n","<summary>Click to view session information</summary>\n","<pre>\n","-----\n","nltk                3.7\n","pandas              1.3.5\n","session_info        1.0.0\n","sklearn             1.0.2\n","-----\n","</pre>\n","<details>\n","<summary>Click to view modules imported as dependencies</summary>\n","<pre>\n","PIL                         7.1.2\n","astor                       0.8.1\n","backcall                    0.2.0\n","beta_ufunc                  NA\n","binom_ufunc                 NA\n","certifi                     2022.06.15\n","cffi                        1.15.1\n","cloudpickle                 1.5.0\n","cycler                      0.10.0\n","cython_runtime              NA\n","dateutil                    2.8.2\n","debugpy                     1.0.0\n","decorator                   4.4.2\n","google                      NA\n","httplib2                    0.17.4\n","ipykernel                   5.3.4\n","ipython_genutils            0.2.0\n","joblib                      1.1.0\n","kiwisolver                  1.4.4\n","matplotlib                  3.2.2\n","mpl_toolkits                NA\n","nbinom_ufunc                NA\n","numexpr                     2.8.3\n","numpy                       1.21.6\n","packaging                   21.3\n","pexpect                     4.8.0\n","pickleshare                 0.7.5\n","pkg_resources               NA\n","portpicker                  NA\n","prompt_toolkit              2.0.10\n","psutil                      5.4.8\n","ptyprocess                  0.7.0\n","pyarrow                     6.0.1\n","pydev_ipython               NA\n","pydevconsole                NA\n","pydevd                      2.0.0\n","pydevd_concurrency_analyser NA\n","pydevd_file_utils           NA\n","pydevd_plugins              NA\n","pydevd_tracing              NA\n","pygments                    2.6.1\n","pyparsing                   3.0.9\n","pytz                        2022.2.1\n","regex                       2.5.115\n","scipy                       1.7.3\n","sitecustomize               NA\n","six                         1.15.0\n","socks                       1.7.1\n","sphinxcontrib               NA\n","storemagic                  NA\n","threadpoolctl               3.1.0\n","tornado                     5.1.1\n","traitlets                   5.1.1\n","typing_extensions           NA\n","wcwidth                     0.2.5\n","zmq                         23.2.1\n","</pre>\n","</details> <!-- seems like this ends pre, so might as well be explicit -->\n","<pre>\n","-----\n","IPython             7.9.0\n","jupyter_client      6.1.12\n","jupyter_core        4.11.1\n","notebook            5.3.1\n","-----\n","Python 3.7.14 (default, Sep  8 2022, 00:06:44) [GCC 7.5.0]\n","Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n","-----\n","Session information updated at 2022-09-29 14:54\n","</pre>\n","</details>"]},"metadata":{},"execution_count":3}],"source":["session_info.show()"]},{"cell_type":"markdown","metadata":{"id":"8WLR_34yw5Iy"},"source":["# Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PFZDVNQhw5I0","executionInfo":{"status":"ok","timestamp":1664463264312,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["data_file = 'DSP453_ClassCorpus_v1.csv'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9lO0cnw4w5I0","executionInfo":{"status":"ok","timestamp":1664463264940,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["class_corpus = pd.read_csv(data_file)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-1s7Lv2w5I1","executionInfo":{"status":"ok","timestamp":1664463266359,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"c1a884b8-5b31-41bb-d096-76e9d0860dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 100 entries, 0 to 99\n","Data columns (total 8 columns):\n"," #   Column                    Non-Null Count  Dtype \n","---  ------                    --------------  ----- \n"," 0   Doc_ID                    100 non-null    int64 \n"," 1   DSI_Title                 100 non-null    object\n"," 2   Text                      100 non-null    object\n"," 3   Submission File Name      100 non-null    object\n"," 4   Student Name              100 non-null    object\n"," 5   Genre of Movie            100 non-null    object\n"," 6   Review Type (pos or neg)  100 non-null    object\n"," 7   Movie Title               100 non-null    object\n","dtypes: int64(1), object(7)\n","memory usage: 6.4+ KB\n"]}],"source":["class_corpus.info()"]},{"cell_type":"markdown","metadata":{"id":"piRTZ-0-w5I2"},"source":["# Data Wrangling"]},{"cell_type":"markdown","source":["To conduct data wrangling using `nltk` we need the following additional modules to be downloaded."],"metadata":{"id":"JnRXGvTayVva"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Br0vfkPxZ57","executionInfo":{"status":"ok","timestamp":1664463272183,"user_tz":-330,"elapsed":1051,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"5ed7ac58-6399-407a-f873-ea8e662af7fb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1wQ8guwBw5I3","executionInfo":{"status":"ok","timestamp":1664463283820,"user_tz":-330,"elapsed":401,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["STOP_WORDS = set(nltk.corpus.stopwords.words('english'))"]},{"cell_type":"markdown","metadata":{"id":"uO1dxV1Cw5I4"},"source":["## Step 1: Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"7cZvnlt9w5I4"},"source":["Below is a set of helper functions that help us format the text of the reviews. "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XgHa2dLWw5I4","executionInfo":{"status":"ok","timestamp":1664463285633,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def remove_punctuation(text):\n","    return re.sub('[^a-zA-Z]', ' ', str(text))\n","\n","def lower_case(text):\n","    return text.lower()    \n","\n","def remove_tags(text):    \n","    return re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \", text)\n","\n","def remove_special_chars_and_digits(text):\n","    return re.sub(\"(\\\\d|\\\\W)+\",\" \", text)\n","\n","def remove_stop_words(tokenized_text):\n","    return [w for w in tokenized_text if not w in STOP_WORDS]"]},{"cell_type":"markdown","metadata":{"id":"Y2KDp9NCw5I5"},"source":["Let us now look at the impact of applying these functions on our reviews text."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gdncN2gAw5I5","executionInfo":{"status":"ok","timestamp":1664463294392,"user_tz":-330,"elapsed":372,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["sample_review_text = class_corpus['Text'][9]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"TqoXTUPcw5I6","executionInfo":{"status":"ok","timestamp":1664463296995,"user_tz":-330,"elapsed":423,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"d49d4519-f727-4151-c42b-6d8401873556"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"While not a perfect movie by any means, there were plenty of funny moments to make this enjoyable. '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["sample_review_text[0:100]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"9pPiM5yRw5I6","executionInfo":{"status":"ok","timestamp":1664463298719,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["normalized_sample_text = remove_punctuation(sample_review_text)\n","normalized_sample_text = lower_case(normalized_sample_text)\n","normalized_sample_text = remove_tags(normalized_sample_text)\n","normalized_sample_text = remove_special_chars_and_digits(normalized_sample_text)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8AW5HfkTw5I6","executionInfo":{"status":"ok","timestamp":1664463300200,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"f08a2e79-12ff-4e12-d6d0-f18c7ea0a7e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["' while not a perfect movie by any means there were plenty of funny moments to make this enjoyable it'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["normalized_sample_text[0:100]"]},{"cell_type":"markdown","metadata":{"id":"ZtOTmbzUw5I7"},"source":["Once the text is free of punctuation, tags and special characters we tokenize the text (i.e., split the text at white spaces). There is a built-in `word_tokenize` function from `nltk` that helps achieve this task."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"OBOISdqGw5I7","executionInfo":{"status":"ok","timestamp":1664463303841,"user_tz":-330,"elapsed":378,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["normalized_sample_tokens = nltk.word_tokenize(normalized_sample_text)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQ5V2n0Xw5I8","executionInfo":{"status":"ok","timestamp":1664463304764,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"62d53f01-8600-4544-889f-e3fa127dc290"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['while',\n"," 'not',\n"," 'a',\n"," 'perfect',\n"," 'movie',\n"," 'by',\n"," 'any',\n"," 'means',\n"," 'there',\n"," 'were',\n"," 'plenty',\n"," 'of',\n"," 'funny',\n"," 'moments',\n"," 'to']"]},"metadata":{},"execution_count":18}],"source":["normalized_sample_tokens[0:15]"]},{"cell_type":"markdown","metadata":{"id":"jJZizAMrw5I8"},"source":["A crucial step after word tokenization is to remove stop words from the tokens generated. "]},{"cell_type":"code","execution_count":19,"metadata":{"id":"6RRzvXKrw5I8","executionInfo":{"status":"ok","timestamp":1664463306840,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["normalized_sample_tokens = remove_stop_words(normalized_sample_tokens)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8uhHumhw5I8","executionInfo":{"status":"ok","timestamp":1664463306840,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"ac467708-ba2b-4109-ea91-680d3bb76ccd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['perfect',\n"," 'movie',\n"," 'means',\n"," 'plenty',\n"," 'funny',\n"," 'moments',\n"," 'make',\n"," 'enjoyable',\n"," 'suppose',\n"," 'everyone',\n"," 'needs',\n"," 'relax',\n"," 'enjoy',\n"," 'life',\n"," 'hilarious']"]},"metadata":{},"execution_count":20}],"source":["normalized_sample_tokens[0:15]"]},{"cell_type":"markdown","metadata":{"id":"zfgPvQKxw5I9"},"source":["## Step 2: Lemmatization"]},{"cell_type":"markdown","metadata":{"id":"6Wek9J15w5I9"},"source":["Once we have the tokens free of stop words, we then consider lemmatization. This helps bring variations of the words to a common base (i.e., the lemma). "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"XrrdpXAHw5I9","executionInfo":{"status":"ok","timestamp":1664463309727,"user_tz":-330,"elapsed":438,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vr9eOnTRw5I9","executionInfo":{"status":"ok","timestamp":1664463311224,"user_tz":-330,"elapsed":1500,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"d2a2dec6-83cf-4c28-951e-48f3a2c89c12"},"outputs":[{"output_type":"stream","name":"stdout","text":["perfect | perfect\n","movie | movie\n","means | mean\n","plenty | plenty\n","funny | funny\n","moments | moment\n","make | make\n","enjoyable | enjoyable\n","suppose | suppose\n","everyone | everyone\n","needs | need\n","relax | relax\n","enjoy | enjoy\n","life | life\n","hilarious | hilarious\n"]}],"source":["for word in normalized_sample_tokens[0:15]:\n","    lemmatized_word = lemmatizer.lemmatize(word)\n","    print(word + ' | ' + lemmatized_word)"]},{"cell_type":"markdown","metadata":{"id":"ukYWgpVtw5I9"},"source":["Detail on [lemmatization and stemming](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20.)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"2OURoCKzw5I-","executionInfo":{"status":"ok","timestamp":1664463314295,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def apply_lemmatization(tokenized_text):\n","    return [lemmatizer.lemmatize(word) for word in tokenized_text]"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbfvzF5_w5I-","executionInfo":{"status":"ok","timestamp":1664463314296,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"2a6fbdcd-12e3-498f-9add-91aa8f71d6b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['perfect',\n"," 'movie',\n"," 'mean',\n"," 'plenty',\n"," 'funny',\n"," 'moment',\n"," 'make',\n"," 'enjoyable',\n"," 'suppose',\n"," 'everyone',\n"," 'need',\n"," 'relax',\n"," 'enjoy',\n"," 'life',\n"," 'hilarious',\n"," 'laughing',\n"," 'entire',\n"," 'time',\n"," 'definitely',\n"," 'tearing',\n"," 'really',\n"," 'needed',\n"," 'great',\n"," 'laugh',\n"," 'movie']"]},"metadata":{},"execution_count":24}],"source":["apply_lemmatization(normalized_sample_tokens)[0:25]"]},{"cell_type":"markdown","metadata":{"id":"ZiwT_K4Mw5I-"},"source":["# Important - Prevalent Terms"]},{"cell_type":"markdown","metadata":{"id":"0M_qIFTrw5I-"},"source":["Exploratory data analysis on text involves getting a sense of tokens that you feel are important (i.e., they represent the *intent* of the corpus) and are prevalent (i.e., they are abundantly represented in the corpus).\n","\n","This is a qualitative exercise. Judgement of what tokens are *important* rests with the analyst."]},{"cell_type":"markdown","metadata":{"id":"WWkm9vT-w5I-"},"source":["Let us apply all the wrangling steps detailed earlier in this notebook to bring the data to a form where we can arrive at important-prevalent terms."]},{"cell_type":"markdown","metadata":{"id":"AadMMTIhw5I_"},"source":["Note that we are about to execute a specific set of data wrangling steps to generate tokens from input text. Changing one or more of the steps followed at this stage will alter the number and variety of the tokens generated."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"O4GLg0CMw5I_","executionInfo":{"status":"ok","timestamp":1664463318465,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def normalize(input_text):\n","    '''\n","    Normalization involves the following steps:\n","    1. Remove punctuation\n","    2. Lower case all words\n","    3. Remove tags (i.e., HTML tags)\n","    4. Remove all special characters and digits\n","    '''\n","    text = remove_punctuation(input_text)\n","    text = lower_case(text)\n","    text = remove_tags(text)\n","    text = remove_special_chars_and_digits(text)\n","\n","    return text"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"0oaMAywAw5I_","executionInfo":{"status":"ok","timestamp":1664463319074,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def tokenize(text):\n","    '''\n","    Tokenization involves the following steps:\n","    1. Break text down to tokens (i.e., words separated by white spaces)\n","    2. Remove stop words from the tokens generated in step 1\n","    '''\n","    tokens = nltk.word_tokenize(text)\n","    tokenized_text = remove_stop_words(tokens)\n","    \n","    return tokenized_text"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"TvqqwOGuw5I_","executionInfo":{"status":"ok","timestamp":1664463319075,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def lemmatize(tokenized_text, lemmatizer=WordNetLemmatizer()):\n","    '''\n","    Lemmatization is applied to each word in the list of normalized tokens\n","    (stop words are removed)\n","    '''\n","    return [lemmatizer.lemmatize(word) for word in tokenized_text]"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"id":"8Sc-U1kCw5I_","executionInfo":{"status":"ok","timestamp":1664463319600,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"68baebe6-0581-41db-d65a-8276f1d97f31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Doc_ID                 DSI_Title  \\\n","0     101  HBW_Doc1_HolmesAndWatson   \n","1     102  HBW_Doc2_HolmesAndWatson   \n","2     103  HBW_Doc3_HolmesAndWatson   \n","3     104  HBW_Doc4_HolmesAndWatson   \n","4     105  HBW_Doc5_HolmesAndWatson   \n","\n","                                                Text  \\\n","0  \"Holmes and Watson review: a lumbering Sherloc...   \n","1  \"ï¿½Holmes & Watsonï¿½ Review: No, Sh-t Sherlo...   \n","2  \"It is often said that Sherlock Holmes, the le...   \n","3  \"Holmes & Watson wasnï¿½t shown at all to the ...   \n","4  \"ï¿½Holmes & Watsonï¿½ Review: Will Ferrell an...   \n","\n","       Submission File Name Student Name Genre of Movie  \\\n","0  HBW_Doc1_HolmesAndWatson          HBW         Comedy   \n","1  HBW_Doc2_HolmesAndWatson          HBW         Comedy   \n","2  HBW_Doc3_HolmesAndWatson          HBW         Comedy   \n","3  HBW_Doc4_HolmesAndWatson          HBW         Comedy   \n","4  HBW_Doc5_HolmesAndWatson          HBW         Comedy   \n","\n","  Review Type (pos or neg)        Movie Title  \n","0                 Negative  Holmes and Watson  \n","1                 Negative  Holmes and Watson  \n","2                 Negative  Holmes and Watson  \n","3                 Negative  Holmes and Watson  \n","4                 Negative  Holmes and Watson  "],"text/html":["\n","  <div id=\"df-8c93b7ce-5f17-420d-a409-0e7ceb4d5cd5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc_ID</th>\n","      <th>DSI_Title</th>\n","      <th>Text</th>\n","      <th>Submission File Name</th>\n","      <th>Student Name</th>\n","      <th>Genre of Movie</th>\n","      <th>Review Type (pos or neg)</th>\n","      <th>Movie Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>\"Holmes and Watson review: a lumbering Sherloc...</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: No, Sh-t Sherlo...</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>\"It is often said that Sherlock Holmes, the le...</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>\"Holmes &amp; Watson wasnï¿½t shown at all to the ...</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: Will Ferrell an...</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c93b7ce-5f17-420d-a409-0e7ceb4d5cd5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8c93b7ce-5f17-420d-a409-0e7ceb4d5cd5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8c93b7ce-5f17-420d-a409-0e7ceb4d5cd5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}],"source":["class_corpus.head()"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"w4Ub06I6w5JA","executionInfo":{"status":"ok","timestamp":1664463329742,"user_tz":-330,"elapsed":469,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["class_corpus['normalized_review'] = class_corpus['Text'].apply(normalize)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"_jRDXfzJw5JA","executionInfo":{"status":"ok","timestamp":1664463332253,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"a38c9ba3-ce83-4024-9f81-726d112e3dfd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Doc_ID                 DSI_Title  \\\n","0     101  HBW_Doc1_HolmesAndWatson   \n","1     102  HBW_Doc2_HolmesAndWatson   \n","2     103  HBW_Doc3_HolmesAndWatson   \n","3     104  HBW_Doc4_HolmesAndWatson   \n","4     105  HBW_Doc5_HolmesAndWatson   \n","\n","                                                Text  \\\n","0  \"Holmes and Watson review: a lumbering Sherloc...   \n","1  \"ï¿½Holmes & Watsonï¿½ Review: No, Sh-t Sherlo...   \n","2  \"It is often said that Sherlock Holmes, the le...   \n","3  \"Holmes & Watson wasnï¿½t shown at all to the ...   \n","4  \"ï¿½Holmes & Watsonï¿½ Review: Will Ferrell an...   \n","\n","       Submission File Name Student Name Genre of Movie  \\\n","0  HBW_Doc1_HolmesAndWatson          HBW         Comedy   \n","1  HBW_Doc2_HolmesAndWatson          HBW         Comedy   \n","2  HBW_Doc3_HolmesAndWatson          HBW         Comedy   \n","3  HBW_Doc4_HolmesAndWatson          HBW         Comedy   \n","4  HBW_Doc5_HolmesAndWatson          HBW         Comedy   \n","\n","  Review Type (pos or neg)        Movie Title  \\\n","0                 Negative  Holmes and Watson   \n","1                 Negative  Holmes and Watson   \n","2                 Negative  Holmes and Watson   \n","3                 Negative  Holmes and Watson   \n","4                 Negative  Holmes and Watson   \n","\n","                                   normalized_review  \n","0   holmes and watson review a lumbering sherlock...  \n","1   holmes watson review no sh t sherlock this wi...  \n","2   it is often said that sherlock holmes the leg...  \n","3   holmes watson wasn t shown at all to the pres...  \n","4   holmes watson review will ferrell and john c ...  "],"text/html":["\n","  <div id=\"df-ef930c4e-2715-4a15-9723-afcc2e5955dd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc_ID</th>\n","      <th>DSI_Title</th>\n","      <th>Text</th>\n","      <th>Submission File Name</th>\n","      <th>Student Name</th>\n","      <th>Genre of Movie</th>\n","      <th>Review Type (pos or neg)</th>\n","      <th>Movie Title</th>\n","      <th>normalized_review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>\"Holmes and Watson review: a lumbering Sherloc...</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes and watson review a lumbering sherlock...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: No, Sh-t Sherlo...</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review no sh t sherlock this wi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>\"It is often said that Sherlock Holmes, the le...</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>it is often said that sherlock holmes the leg...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>\"Holmes &amp; Watson wasnï¿½t shown at all to the ...</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson wasn t shown at all to the pres...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: Will Ferrell an...</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review will ferrell and john c ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef930c4e-2715-4a15-9723-afcc2e5955dd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ef930c4e-2715-4a15-9723-afcc2e5955dd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ef930c4e-2715-4a15-9723-afcc2e5955dd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}],"source":["class_corpus.head()"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"P6MGCl5gw5JA","executionInfo":{"status":"ok","timestamp":1664463332889,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["class_corpus['tokenized_review'] = class_corpus['normalized_review'].apply(tokenize)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563},"id":"vRjCEkc2w5JB","executionInfo":{"status":"ok","timestamp":1664463333898,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"6bc154ef-53de-48c2-8c7c-511f17d76f31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Doc_ID                 DSI_Title  \\\n","0     101  HBW_Doc1_HolmesAndWatson   \n","1     102  HBW_Doc2_HolmesAndWatson   \n","2     103  HBW_Doc3_HolmesAndWatson   \n","3     104  HBW_Doc4_HolmesAndWatson   \n","4     105  HBW_Doc5_HolmesAndWatson   \n","\n","                                                Text  \\\n","0  \"Holmes and Watson review: a lumbering Sherloc...   \n","1  \"ï¿½Holmes & Watsonï¿½ Review: No, Sh-t Sherlo...   \n","2  \"It is often said that Sherlock Holmes, the le...   \n","3  \"Holmes & Watson wasnï¿½t shown at all to the ...   \n","4  \"ï¿½Holmes & Watsonï¿½ Review: Will Ferrell an...   \n","\n","       Submission File Name Student Name Genre of Movie  \\\n","0  HBW_Doc1_HolmesAndWatson          HBW         Comedy   \n","1  HBW_Doc2_HolmesAndWatson          HBW         Comedy   \n","2  HBW_Doc3_HolmesAndWatson          HBW         Comedy   \n","3  HBW_Doc4_HolmesAndWatson          HBW         Comedy   \n","4  HBW_Doc5_HolmesAndWatson          HBW         Comedy   \n","\n","  Review Type (pos or neg)        Movie Title  \\\n","0                 Negative  Holmes and Watson   \n","1                 Negative  Holmes and Watson   \n","2                 Negative  Holmes and Watson   \n","3                 Negative  Holmes and Watson   \n","4                 Negative  Holmes and Watson   \n","\n","                                   normalized_review  \\\n","0   holmes and watson review a lumbering sherlock...   \n","1   holmes watson review no sh t sherlock this wi...   \n","2   it is often said that sherlock holmes the leg...   \n","3   holmes watson wasn t shown at all to the pres...   \n","4   holmes watson review will ferrell and john c ...   \n","\n","                                    tokenized_review  \n","0  [holmes, watson, review, lumbering, sherlockia...  \n","1  [holmes, watson, review, sh, sherlock, ferrell...  \n","2  [often, said, sherlock, holmes, legendary, det...  \n","3  [holmes, watson, shown, press, advance, releas...  \n","4  [holmes, watson, review, ferrell, john, c, rei...  "],"text/html":["\n","  <div id=\"df-3feb23a7-c98b-4b96-b3a2-09c88335863e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc_ID</th>\n","      <th>DSI_Title</th>\n","      <th>Text</th>\n","      <th>Submission File Name</th>\n","      <th>Student Name</th>\n","      <th>Genre of Movie</th>\n","      <th>Review Type (pos or neg)</th>\n","      <th>Movie Title</th>\n","      <th>normalized_review</th>\n","      <th>tokenized_review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>\"Holmes and Watson review: a lumbering Sherloc...</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes and watson review a lumbering sherlock...</td>\n","      <td>[holmes, watson, review, lumbering, sherlockia...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: No, Sh-t Sherlo...</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review no sh t sherlock this wi...</td>\n","      <td>[holmes, watson, review, sh, sherlock, ferrell...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>\"It is often said that Sherlock Holmes, the le...</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>it is often said that sherlock holmes the leg...</td>\n","      <td>[often, said, sherlock, holmes, legendary, det...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>\"Holmes &amp; Watson wasnï¿½t shown at all to the ...</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson wasn t shown at all to the pres...</td>\n","      <td>[holmes, watson, shown, press, advance, releas...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: Will Ferrell an...</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review will ferrell and john c ...</td>\n","      <td>[holmes, watson, review, ferrell, john, c, rei...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3feb23a7-c98b-4b96-b3a2-09c88335863e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3feb23a7-c98b-4b96-b3a2-09c88335863e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3feb23a7-c98b-4b96-b3a2-09c88335863e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}],"source":["class_corpus.head()"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"qLhi3bvjw5JB","executionInfo":{"status":"ok","timestamp":1664463335947,"user_tz":-330,"elapsed":581,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["class_corpus['lemmatized_tokens'] = class_corpus['tokenized_review'].apply(lemmatize)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"id":"87HUmbNKw5JB","executionInfo":{"status":"ok","timestamp":1664463338209,"user_tz":-330,"elapsed":619,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"179d4b8c-a8b1-4394-a55e-306e3af34a4f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Doc_ID                 DSI_Title  \\\n","0     101  HBW_Doc1_HolmesAndWatson   \n","1     102  HBW_Doc2_HolmesAndWatson   \n","2     103  HBW_Doc3_HolmesAndWatson   \n","3     104  HBW_Doc4_HolmesAndWatson   \n","4     105  HBW_Doc5_HolmesAndWatson   \n","\n","                                                Text  \\\n","0  \"Holmes and Watson review: a lumbering Sherloc...   \n","1  \"ï¿½Holmes & Watsonï¿½ Review: No, Sh-t Sherlo...   \n","2  \"It is often said that Sherlock Holmes, the le...   \n","3  \"Holmes & Watson wasnï¿½t shown at all to the ...   \n","4  \"ï¿½Holmes & Watsonï¿½ Review: Will Ferrell an...   \n","\n","       Submission File Name Student Name Genre of Movie  \\\n","0  HBW_Doc1_HolmesAndWatson          HBW         Comedy   \n","1  HBW_Doc2_HolmesAndWatson          HBW         Comedy   \n","2  HBW_Doc3_HolmesAndWatson          HBW         Comedy   \n","3  HBW_Doc4_HolmesAndWatson          HBW         Comedy   \n","4  HBW_Doc5_HolmesAndWatson          HBW         Comedy   \n","\n","  Review Type (pos or neg)        Movie Title  \\\n","0                 Negative  Holmes and Watson   \n","1                 Negative  Holmes and Watson   \n","2                 Negative  Holmes and Watson   \n","3                 Negative  Holmes and Watson   \n","4                 Negative  Holmes and Watson   \n","\n","                                   normalized_review  \\\n","0   holmes and watson review a lumbering sherlock...   \n","1   holmes watson review no sh t sherlock this wi...   \n","2   it is often said that sherlock holmes the leg...   \n","3   holmes watson wasn t shown at all to the pres...   \n","4   holmes watson review will ferrell and john c ...   \n","\n","                                    tokenized_review  \\\n","0  [holmes, watson, review, lumbering, sherlockia...   \n","1  [holmes, watson, review, sh, sherlock, ferrell...   \n","2  [often, said, sherlock, holmes, legendary, det...   \n","3  [holmes, watson, shown, press, advance, releas...   \n","4  [holmes, watson, review, ferrell, john, c, rei...   \n","\n","                                   lemmatized_tokens  \n","0  [holmes, watson, review, lumbering, sherlockia...  \n","1  [holmes, watson, review, sh, sherlock, ferrell...  \n","2  [often, said, sherlock, holmes, legendary, det...  \n","3  [holmes, watson, shown, press, advance, releas...  \n","4  [holmes, watson, review, ferrell, john, c, rei...  "],"text/html":["\n","  <div id=\"df-80b3d9d0-f5db-4f8d-a1dd-78752556cec5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc_ID</th>\n","      <th>DSI_Title</th>\n","      <th>Text</th>\n","      <th>Submission File Name</th>\n","      <th>Student Name</th>\n","      <th>Genre of Movie</th>\n","      <th>Review Type (pos or neg)</th>\n","      <th>Movie Title</th>\n","      <th>normalized_review</th>\n","      <th>tokenized_review</th>\n","      <th>lemmatized_tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>\"Holmes and Watson review: a lumbering Sherloc...</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes and watson review a lumbering sherlock...</td>\n","      <td>[holmes, watson, review, lumbering, sherlockia...</td>\n","      <td>[holmes, watson, review, lumbering, sherlockia...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: No, Sh-t Sherlo...</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review no sh t sherlock this wi...</td>\n","      <td>[holmes, watson, review, sh, sherlock, ferrell...</td>\n","      <td>[holmes, watson, review, sh, sherlock, ferrell...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>\"It is often said that Sherlock Holmes, the le...</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>it is often said that sherlock holmes the leg...</td>\n","      <td>[often, said, sherlock, holmes, legendary, det...</td>\n","      <td>[often, said, sherlock, holmes, legendary, det...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>\"Holmes &amp; Watson wasnï¿½t shown at all to the ...</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson wasn t shown at all to the pres...</td>\n","      <td>[holmes, watson, shown, press, advance, releas...</td>\n","      <td>[holmes, watson, shown, press, advance, releas...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: Will Ferrell an...</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review will ferrell and john c ...</td>\n","      <td>[holmes, watson, review, ferrell, john, c, rei...</td>\n","      <td>[holmes, watson, review, ferrell, john, c, rei...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b3d9d0-f5db-4f8d-a1dd-78752556cec5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80b3d9d0-f5db-4f8d-a1dd-78752556cec5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80b3d9d0-f5db-4f8d-a1dd-78752556cec5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}],"source":["class_corpus.head()"]},{"cell_type":"markdown","metadata":{"id":"BhQHYiQ5w5JB"},"source":["To count the occurrences of each token across the corpus we use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from scikit-learn."]},{"cell_type":"markdown","metadata":{"id":"G8iVfCKrw5JC"},"source":["To be able to use the count vectorizer, we need the corpus to be a list of sentences. Let us apply this to the lemmatized review column in the class corpus."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"JWtOVSQPw5JC","executionInfo":{"status":"ok","timestamp":1664463340917,"user_tz":-330,"elapsed":422,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["def join_tokens(lemmatized_tokens):\n","    return ' '.join(lemmatized_tokens)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"aihXcpE2w5JC","executionInfo":{"status":"ok","timestamp":1664463341693,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["class_corpus['lemmatized_text'] = class_corpus['lemmatized_tokens'].apply(join_tokens)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"id":"p00gmM6Hw5JC","executionInfo":{"status":"ok","timestamp":1664463342309,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"f59bfb59-dd45-4cd1-8db9-75c8f2d59f5b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Doc_ID                 DSI_Title  \\\n","0     101  HBW_Doc1_HolmesAndWatson   \n","1     102  HBW_Doc2_HolmesAndWatson   \n","2     103  HBW_Doc3_HolmesAndWatson   \n","3     104  HBW_Doc4_HolmesAndWatson   \n","4     105  HBW_Doc5_HolmesAndWatson   \n","\n","                                                Text  \\\n","0  \"Holmes and Watson review: a lumbering Sherloc...   \n","1  \"ï¿½Holmes & Watsonï¿½ Review: No, Sh-t Sherlo...   \n","2  \"It is often said that Sherlock Holmes, the le...   \n","3  \"Holmes & Watson wasnï¿½t shown at all to the ...   \n","4  \"ï¿½Holmes & Watsonï¿½ Review: Will Ferrell an...   \n","\n","       Submission File Name Student Name Genre of Movie  \\\n","0  HBW_Doc1_HolmesAndWatson          HBW         Comedy   \n","1  HBW_Doc2_HolmesAndWatson          HBW         Comedy   \n","2  HBW_Doc3_HolmesAndWatson          HBW         Comedy   \n","3  HBW_Doc4_HolmesAndWatson          HBW         Comedy   \n","4  HBW_Doc5_HolmesAndWatson          HBW         Comedy   \n","\n","  Review Type (pos or neg)        Movie Title  \\\n","0                 Negative  Holmes and Watson   \n","1                 Negative  Holmes and Watson   \n","2                 Negative  Holmes and Watson   \n","3                 Negative  Holmes and Watson   \n","4                 Negative  Holmes and Watson   \n","\n","                                   normalized_review  \\\n","0   holmes and watson review a lumbering sherlock...   \n","1   holmes watson review no sh t sherlock this wi...   \n","2   it is often said that sherlock holmes the leg...   \n","3   holmes watson wasn t shown at all to the pres...   \n","4   holmes watson review will ferrell and john c ...   \n","\n","                                    tokenized_review  \\\n","0  [holmes, watson, review, lumbering, sherlockia...   \n","1  [holmes, watson, review, sh, sherlock, ferrell...   \n","2  [often, said, sherlock, holmes, legendary, det...   \n","3  [holmes, watson, shown, press, advance, releas...   \n","4  [holmes, watson, review, ferrell, john, c, rei...   \n","\n","                                   lemmatized_tokens  \\\n","0  [holmes, watson, review, lumbering, sherlockia...   \n","1  [holmes, watson, review, sh, sherlock, ferrell...   \n","2  [often, said, sherlock, holmes, legendary, det...   \n","3  [holmes, watson, shown, press, advance, releas...   \n","4  [holmes, watson, review, ferrell, john, c, rei...   \n","\n","                                     lemmatized_text  \n","0  holmes watson review lumbering sherlockian kno...  \n","1  holmes watson review sh sherlock ferrell john ...  \n","2  often said sherlock holmes legendary detective...  \n","3  holmes watson shown press advance release one ...  \n","4  holmes watson review ferrell john c reilly fai...  "],"text/html":["\n","  <div id=\"df-b65b9471-703f-41eb-90a2-ad59313cb352\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc_ID</th>\n","      <th>DSI_Title</th>\n","      <th>Text</th>\n","      <th>Submission File Name</th>\n","      <th>Student Name</th>\n","      <th>Genre of Movie</th>\n","      <th>Review Type (pos or neg)</th>\n","      <th>Movie Title</th>\n","      <th>normalized_review</th>\n","      <th>tokenized_review</th>\n","      <th>lemmatized_tokens</th>\n","      <th>lemmatized_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>\"Holmes and Watson review: a lumbering Sherloc...</td>\n","      <td>HBW_Doc1_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes and watson review a lumbering sherlock...</td>\n","      <td>[holmes, watson, review, lumbering, sherlockia...</td>\n","      <td>[holmes, watson, review, lumbering, sherlockia...</td>\n","      <td>holmes watson review lumbering sherlockian kno...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: No, Sh-t Sherlo...</td>\n","      <td>HBW_Doc2_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review no sh t sherlock this wi...</td>\n","      <td>[holmes, watson, review, sh, sherlock, ferrell...</td>\n","      <td>[holmes, watson, review, sh, sherlock, ferrell...</td>\n","      <td>holmes watson review sh sherlock ferrell john ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>\"It is often said that Sherlock Holmes, the le...</td>\n","      <td>HBW_Doc3_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>it is often said that sherlock holmes the leg...</td>\n","      <td>[often, said, sherlock, holmes, legendary, det...</td>\n","      <td>[often, said, sherlock, holmes, legendary, det...</td>\n","      <td>often said sherlock holmes legendary detective...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>\"Holmes &amp; Watson wasnï¿½t shown at all to the ...</td>\n","      <td>HBW_Doc4_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson wasn t shown at all to the pres...</td>\n","      <td>[holmes, watson, shown, press, advance, releas...</td>\n","      <td>[holmes, watson, shown, press, advance, releas...</td>\n","      <td>holmes watson shown press advance release one ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>\"ï¿½Holmes &amp; Watsonï¿½ Review: Will Ferrell an...</td>\n","      <td>HBW_Doc5_HolmesAndWatson</td>\n","      <td>HBW</td>\n","      <td>Comedy</td>\n","      <td>Negative</td>\n","      <td>Holmes and Watson</td>\n","      <td>holmes watson review will ferrell and john c ...</td>\n","      <td>[holmes, watson, review, ferrell, john, c, rei...</td>\n","      <td>[holmes, watson, review, ferrell, john, c, rei...</td>\n","      <td>holmes watson review ferrell john c reilly fai...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b65b9471-703f-41eb-90a2-ad59313cb352')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b65b9471-703f-41eb-90a2-ad59313cb352 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b65b9471-703f-41eb-90a2-ad59313cb352');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}],"source":["class_corpus.head()"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"3_45_iVZw5JD","executionInfo":{"status":"ok","timestamp":1664463343984,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["count_vectorizer = CountVectorizer()"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"E1T9SrSaw5JD","executionInfo":{"status":"ok","timestamp":1664463345113,"user_tz":-330,"elapsed":1,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["dtm_class_corpus = count_vectorizer.fit_transform(class_corpus['lemmatized_text'])"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"jtQbgheEw5JD","executionInfo":{"status":"ok","timestamp":1664463345757,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}}},"outputs":[],"source":["word_counts_class_corpus = pd.DataFrame(dtm_class_corpus.toarray(), \n","                                        columns=count_vectorizer.get_feature_names_out(), \n","                                        index=class_corpus.index)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"-ti5dCWGw5JD","executionInfo":{"status":"ok","timestamp":1664463347535,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"f349a13a-c8f3-4755-af95-c8a10c9214d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   aaannyway  abandon  abandoned  abc  abduct  abducted  abductor  abel  \\\n","0          0        0          0    0       0         0         0     0   \n","1          0        0          0    0       0         0         0     0   \n","2          0        0          0    0       0         0         0     0   \n","3          0        0          1    0       0         0         0     0   \n","4          0        0          0    0       0         0         0     0   \n","\n","   aberration  ability  ...  zimmer  zippier  zipping  zippo  zoey  zombie  \\\n","0           0        0  ...       0        0        0      0     0       0   \n","1           0        0  ...       0        0        0      0     0       0   \n","2           0        0  ...       0        0        0      0     0       0   \n","3           0        0  ...       0        0        0      0     0       0   \n","4           0        0  ...       0        0        0      0     0       0   \n","\n","   zombified  zone  zoolander  zora  \n","0          0     1          0     0  \n","1          0     0          0     0  \n","2          0     0          0     0  \n","3          0     0          0     0  \n","4          0     0          0     0  \n","\n","[5 rows x 8799 columns]"],"text/html":["\n","  <div id=\"df-2d7a72fe-e95d-4708-bfa5-8f5e91c12a28\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aaannyway</th>\n","      <th>abandon</th>\n","      <th>abandoned</th>\n","      <th>abc</th>\n","      <th>abduct</th>\n","      <th>abducted</th>\n","      <th>abductor</th>\n","      <th>abel</th>\n","      <th>aberration</th>\n","      <th>ability</th>\n","      <th>...</th>\n","      <th>zimmer</th>\n","      <th>zippier</th>\n","      <th>zipping</th>\n","      <th>zippo</th>\n","      <th>zoey</th>\n","      <th>zombie</th>\n","      <th>zombified</th>\n","      <th>zone</th>\n","      <th>zoolander</th>\n","      <th>zora</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 8799 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d7a72fe-e95d-4708-bfa5-8f5e91c12a28')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d7a72fe-e95d-4708-bfa5-8f5e91c12a28 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d7a72fe-e95d-4708-bfa5-8f5e91c12a28');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":42}],"source":["word_counts_class_corpus.head()"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHsWcfvxw5JE","executionInfo":{"status":"ok","timestamp":1664463349027,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pavankumar Gurazada","userId":"10690826909418856210"}},"outputId":"6b3366d5-8516-4bc9-d9bc-666e6e0129e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["movie        466\n","film         445\n","one          323\n","time         252\n","like         228\n","get          192\n","bond         181\n","even         158\n","scene        146\n","make         143\n","character    141\n","good         132\n","story        127\n","much         118\n","go           118\n","also         114\n","way          114\n","would        108\n","holmes       103\n","thing        100\n","take          99\n","year          97\n","action        96\n","first         95\n","really        92\n","dtype: int64"]},"metadata":{},"execution_count":43}],"source":["(word_counts_class_corpus.sum()\n","                         .sort_values(ascending=False)\n","                         .head(25))"]},{"cell_type":"markdown","metadata":{"id":"wmMQm62lw5JE"},"source":["Based on these prevalent terms, we will need to take a call on which of these are also important in the context of the movie reviews."]},{"cell_type":"markdown","metadata":{"id":"AxLKnvGtw5JE"},"source":["# Summary"]},{"cell_type":"markdown","metadata":{"id":"1OK5Se2kw5JE"},"source":["Data wrangling in the context of text as input comes down to a two stage process:\n","1. Pre-processing (or *Normalizing*) the text by removing punctuation, tags & special characters, lower casing the words and removing the stop words. The end result at this point is a list of tokens for each review.\n","2. *Lemmatization* applied on the normalized list of tokens to bring them down to a common lemma. "]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('aimlclasses')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"3c1e73e333da691d1541ae9459c12b06f935e3cff125444867bb111cd49f9379"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}